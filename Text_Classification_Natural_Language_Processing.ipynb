{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlUii9Q2sgmYmGZi138Ph7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niroth36/Text_Classification_Natural_Language_Processing/blob/main/Text_Classification_Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "7GlzBw-msEmd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fWa6qcEQfHXW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "\n",
        "from keras import layers\n",
        "from keras import losses\n",
        "from keras import preprocessing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing dataset"
      ],
      "metadata": {
        "id": "RJt2CKlusQW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the CSV file"
      ],
      "metadata": {
        "id": "CuEH9BAqvOKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/Niroth36/Text_Classification_Natural_Language_Processing/main/dataset.csv.gz\"\n",
        "filename = \"dataset.csv.gz\"\n",
        "\n",
        "path = tf.keras.utils.get_file(filename, url)"
      ],
      "metadata": {
        "id": "FTGnA4TxsTJF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the file and read the CSV file using pandas"
      ],
      "metadata": {
        "id": "pKcACLpE-_6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path, compression='gzip')"
      ],
      "metadata": {
        "id": "pRAgD5SR-_Kj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "urScw2vMx9bz",
        "outputId": "58f30937-a728-425e-baa3-1a8fcca4f810"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Release Year                            Title Origin/Ethnicity  \\\n",
              "0           6          1903          The Great Train Robbery         American   \n",
              "1           7          1904                  The Suburbanite         American   \n",
              "2          13          1907                     Daniel Boone         American   \n",
              "3          14          1907  How Brown Saw the Baseball Game         American   \n",
              "4          15          1907                     Laughing Gas         American   \n",
              "\n",
              "                                  Director  \\\n",
              "0                          Edwin S. Porter   \n",
              "1                       Wallace McCutcheon   \n",
              "2  Wallace McCutcheon and Ediwin S. Porter   \n",
              "3                                  Unknown   \n",
              "4                     Edwin Stanton Porter   \n",
              "\n",
              "                                           Wiki Page  \\\n",
              "0  https://en.wikipedia.org/wiki/The_Great_Train_...   \n",
              "1      https://en.wikipedia.org/wiki/The_Suburbanite   \n",
              "2  https://en.wikipedia.org/wiki/Daniel_Boone_(19...   \n",
              "3  https://en.wikipedia.org/wiki/How_Brown_Saw_th...   \n",
              "4  https://en.wikipedia.org/wiki/Laughing_Gas_(fi...   \n",
              "\n",
              "                                                Plot      Genre  \n",
              "0  The film opens with two bandits breaking into ...     action  \n",
              "1  The film is about a family who move to the sub...     comedy  \n",
              "2  Boone's daughter befriends an Indian maiden as...  biography  \n",
              "3  Before heading out to a baseball game at a nea...     comedy  \n",
              "4  The plot is that of a black woman going to the...     comedy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a36d9954-5821-4a49-a531-09dcfddb1c44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Release Year</th>\n",
              "      <th>Title</th>\n",
              "      <th>Origin/Ethnicity</th>\n",
              "      <th>Director</th>\n",
              "      <th>Wiki Page</th>\n",
              "      <th>Plot</th>\n",
              "      <th>Genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>1903</td>\n",
              "      <td>The Great Train Robbery</td>\n",
              "      <td>American</td>\n",
              "      <td>Edwin S. Porter</td>\n",
              "      <td>https://en.wikipedia.org/wiki/The_Great_Train_...</td>\n",
              "      <td>The film opens with two bandits breaking into ...</td>\n",
              "      <td>action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>1904</td>\n",
              "      <td>The Suburbanite</td>\n",
              "      <td>American</td>\n",
              "      <td>Wallace McCutcheon</td>\n",
              "      <td>https://en.wikipedia.org/wiki/The_Suburbanite</td>\n",
              "      <td>The film is about a family who move to the sub...</td>\n",
              "      <td>comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>1907</td>\n",
              "      <td>Daniel Boone</td>\n",
              "      <td>American</td>\n",
              "      <td>Wallace McCutcheon and Ediwin S. Porter</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Daniel_Boone_(19...</td>\n",
              "      <td>Boone's daughter befriends an Indian maiden as...</td>\n",
              "      <td>biography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14</td>\n",
              "      <td>1907</td>\n",
              "      <td>How Brown Saw the Baseball Game</td>\n",
              "      <td>American</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>https://en.wikipedia.org/wiki/How_Brown_Saw_th...</td>\n",
              "      <td>Before heading out to a baseball game at a nea...</td>\n",
              "      <td>comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>1907</td>\n",
              "      <td>Laughing Gas</td>\n",
              "      <td>American</td>\n",
              "      <td>Edwin Stanton Porter</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Laughing_Gas_(fi...</td>\n",
              "      <td>The plot is that of a black woman going to the...</td>\n",
              "      <td>comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a36d9954-5821-4a49-a531-09dcfddb1c44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a36d9954-5821-4a49-a531-09dcfddb1c44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a36d9954-5821-4a49-a531-09dcfddb1c44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "44r1IzRZCRSl",
        "outputId": "f36a220a-b55e-4ebf-f910-fd04ab166fa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23025 entries, 0 to 23024\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   Unnamed: 0        23025 non-null  int64 \n",
            " 1   Release Year      23025 non-null  int64 \n",
            " 2   Title             23025 non-null  object\n",
            " 3   Origin/Ethnicity  23025 non-null  object\n",
            " 4   Director          23025 non-null  object\n",
            " 5   Cast              22539 non-null  object\n",
            " 6   Wiki Page         23025 non-null  object\n",
            " 7   Plot              23025 non-null  object\n",
            " 8   Genre             23025 non-null  object\n",
            "dtypes: int64(2), object(7)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "RBPLObksCjIR",
        "outputId": "75bf2c7a-2b9a-4740-c580-a5228f436a4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0          0\n",
              "Release Year        0\n",
              "Title               0\n",
              "Origin/Ethnicity    0\n",
              "Director            0\n",
              "Wiki Page           0\n",
              "Plot                0\n",
              "Genre               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I decided to drop Cast column because it has missing values and it has no point in categorizing the movies according to their genre."
      ],
      "metadata": {
        "id": "-pofsP5Oj20v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.drop(\"Cast\", axis='columns')"
      ],
      "metadata": {
        "id": "CoCKmcTNjsHS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function should load the data from the CSV file at file_path, preprocess it as described, and return three tf.data.Dataset objects for training, validation, and testing, respectively. The batch_size, p_train, and p_val parameters control the size of the batches and the proportion of the data used for training, validation, and testing, respectively. The function also returns the number of labels in the dataset as n_labels."
      ],
      "metadata": {
        "id": "7j6XHU64Deeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_wiki(file_path, batch_size=32, p_train=.65, p_val=0.15):\n",
        "    # load data with pandas\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # randomize the data\n",
        "    df = df.sample(frac=1, random_state=42)\n",
        "\n",
        "    # convert Origin/Ethnicity to one-hot encoding\n",
        "    ethnicity_onehot = pd.get_dummies(df['Origin/Ethnicity'], prefix='Ethnicity')\n",
        "\n",
        "    # concatenate the data and one-hot encoded ethnicity\n",
        "    df = pd.concat([df, ethnicity_onehot], axis=1)\n",
        "\n",
        "    # convert the genre labels to integer IDs\n",
        "    genre2id = {g: i for i, g in enumerate(sorted(df['Genre'].unique()))}\n",
        "    df['label'] = df['Genre'].map(genre2id)\n",
        "\n",
        "    # split data into train, val, and test\n",
        "    train_size = int(p_train * len(df))\n",
        "    val_size = int(p_val * len(df))\n",
        "    test_size = len(df) - train_size - val_size\n",
        "\n",
        "    train_df = df[:train_size]\n",
        "    val_df = df[train_size:train_size + val_size]\n",
        "    test_df = df[train_size + val_size:]\n",
        "\n",
        "    # convert dataframes to dictionaries\n",
        "    train_data = dict(train_df[['Title', 'Plot', 'Ethnicity_American', 'Ethnicity_British', 'Ethnicity_Indian', 'Ethnicity_Other']].items())\n",
        "    train_data['label'] = np.array(train_df['label'].tolist())\n",
        "\n",
        "    val_data = dict(val_df[['Title', 'Plot', 'Ethnicity_American', 'Ethnicity_British', 'Ethnicity_Indian', 'Ethnicity_Other']].items())\n",
        "    val_data['label'] = np.array(val_df['label'].tolist())\n",
        "\n",
        "    test_data = dict(test_df[['Title', 'Plot', 'Ethnicity_American', 'Ethnicity_British', 'Ethnicity_Indian', 'Ethnicity_Other']].items())\n",
        "    test_data['label'] = np.array(test_df['label'].tolist())\n",
        "\n",
        "    # create tf.data.Dataset objects\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(train_data)\n",
        "    train_ds = train_ds.shuffle(buffer_size=train_size)\n",
        "    train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices(val_data)\n",
        "    val_ds = val_ds.shuffle(buffer_size=val_size)\n",
        "    val_ds = val_ds.batch(batch_size)\n",
        "\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices(test_data)\n",
        "    test_ds = test_ds.batch(batch_size)\n",
        "\n",
        "    # return datasets and number of labels\n",
        "    return train_ds, val_ds, test_ds, len(genre2id)\n"
      ],
      "metadata": {
        "id": "CLALK_idCzmO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def preprocess_titles(title):\n",
        "    # Convert to lowercase\n",
        "    title = title.lower()\n",
        "    # Remove punctuation\n",
        "    title = title.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove numbers\n",
        "    title = re.sub(r'\\d+', '', title)\n",
        "    # Split into words\n",
        "    title_words = title.split()\n",
        "    # Remove stop words\n",
        "    stop_words = set(['a', 'an', 'and', 'the', 'of', 'in', 'on', 'at', 'is'])\n",
        "    title_words = [word for word in title_words if word not in stop_words]\n",
        "    # Return preprocessed title as string\n",
        "    return ' '.join(title_words)\n"
      ],
      "metadata": {
        "id": "Et7HvnORGfoh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the movie plots dataset\n",
        "df = pd.read_csv(path, compression='gzip')\n",
        "\n",
        "# Preprocess the titles column\n",
        "def preprocess_titles(title):\n",
        "    # Remove parentheses and their contents\n",
        "    title = re.sub(r'\\([^)]*\\)', '', title)\n",
        "    # Remove any remaining punctuation\n",
        "    title = re.sub(r'[^\\w\\s]', '', title)\n",
        "    # Convert to lowercase\n",
        "    title = title.lower()\n",
        "    return title\n",
        "\n",
        "df['Title'] = df['Title'].apply(preprocess_titles)\n",
        "\n",
        "# Convert Origin/Ethnicity and Genre to one-hot encoded variables\n",
        "df = pd.get_dummies(df, columns=['Origin/Ethnicity', 'Genre'])\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_df, val_df, test_df = np.split(df.sample(frac=1, random_state=42), [int(0.6*len(df)), int(0.8*len(df))])\n",
        "\n",
        "# Convert the dataframes to dictionaries\n",
        "train_dict = {'Title': train_df['Title'].values, 'Origin/Ethnicity': train_df.filter(like='Origin/Ethnicity').values.astype(np.float64), 'Plot': train_df['Plot'].values, 'Genre': train_df.filter(like='Genre').values.astype(np.float64)}\n",
        "val_dict = {'Title': val_df['Title'].values, 'Origin/Ethnicity': val_df.filter(like='Origin/Ethnicity').values.astype(np.float64), 'Plot': val_df['Plot'].values, 'Genre': val_df.filter(like='Genre').values.astype(np.float64)}\n",
        "test_dict = {'Title': test_df['Title'].values, 'Origin/Ethnicity': test_df.filter(like='Origin/Ethnicity').values.astype(np.float64), 'Plot': test_df['Plot'].values, 'Genre': test_df.filter(like='Genre').values.astype(np.float64)}\n",
        "\n",
        "# Create tf.data.Dataset objects from the dictionaries\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_dict)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(val_dict)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test_dict)\n",
        "\n",
        "# Print the first few entries in the training dataset\n",
        "for elem in train_dataset.take(5):\n",
        "    print(elem)\n"
      ],
      "metadata": {
        "id": "jNkKdztvR_VT",
        "outputId": "1f6b9cd4-3fb4-4a3b-a1f8-cd34360ac4ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'creature with the atom brain'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b\"A hulking zombie breaks into a mansion and kills a gangster named Hennesy. The blood stains left behind at the crime scene are radioactive, and the fingerprints of the killer are of a man who had died days before the murder; the police are baffled.\\r\\nGangster boss Frank Buchanan, who had been forced to flee the United States before he was deported, was betrayed by members of his own underworld gang. While traveling in Europe, he finds ex-Nazi scientist Wilhelm Steigg (Gaye), who is trying to reanimate the dead in order to provide a menial labor pool that is easily exploited. Buchanan funds the research and brings the scientist to America with the unstated goal of sending Steigg's zombies out to murder those who ousted him; one by one, they are killed in the same fashion.\\r\\nThe police eventually discover the common connection between the murdered gang members and Buchanan. They try to put the remaining three into protective custody, but Buchanan uses a reanimated dead cop to kill one of them, and a reanimated dead police captain to kill the remaining two. When the zombie captain is captured, police doctor, Dr. Chet Walker (Denning) discovers an atomic-powered remote control brain implant and deduces what has been going on.\\r\\nPolice and army troops converge on Buchanan's lead-lined mansion, and he sends out his unkillable zombies to battle them. Walker, however, is able to get into the mansion and smash the atomic-powered equipment that controls the zombies; after doing so, they all collapse. Buchanan is about to shoot Walker, but the still-animated zombie police captain, now under Walker's control, grabs and strangles Buchanan before he can fire a shot.\">, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.])>}\n",
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'son of paleface'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b'Peter \"Junior\" Potter (Hope) has graduated from Harvard and now heads west to the town of Sawbuck Pass to claim his Daddy\\'s fortune. Driving into town in a jalopy and wearing a comical plaid suit, he splashes mud all over a crowd of townspeople. He also discovers to his horror that practically everyone in town claims to be owed a debt, and that his father\\'s treasure chest is empty.\\r\\nJunior stalls the townfolk for as long as he can, continually making allusions to his wealth. He makes the acquaintance of a singing cowboy named Roy (Rogers) and a sexy saloon performer with the masculine name of Mike (Russell), who has to fend off Junior\\'s persistent advances. A grizzled local character also befriends Junior and continues offering him advice, eventually finding the hiding place of his father\\'s hidden fortune. Meanwhile, a mysterious masked bandit known only as \"The Torch\" has been leading midnight raids.\\r\\nWhat the wise-cracking, clueless Junior doesn\\'t know is that the object of his affections, Mike, is in fact The Torch, and that Roy is a government agent with a Smith & Wesson Model 320 Revolving Rifle hidden in his guitar case, bent on capturing her.'>, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.])>}\n",
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'the lady with a lamp'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b'Illustrating the political complexities the hard-headed nurse had to battle in order to achieve sanitary medical conditions during the Crimean War. Opposed in the uppermost circles of British government because she is \"merely\" a woman, Florence Nightingale is championed by the Hon. Sidney Herbert (Michael Wilding), minister of war. Herbert pulls strings to allow Nightingale and her nursing staff access to battlefield hospitals, and in so doing changes the course of medical history.[3]'>, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.])>}\n",
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'felix and meira'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b\"In Mile End, Montreal, a Hassidic Jewish woman named Meira lives a miserable life, married to Shulem who does not allow her to listen to secular music. They have a young daughter named Elishiva, but Meira confides in her friend that she does not want any more children, despite their religious duty. Word reaches Shulem, who berates Meira for shaming the small family. By chance, Meira meets F\\xc3\\xa9lix, a French Canadian man who has just lost his father Th\\xc3\\xa9odore, who at the end of his life no longer knew F\\xc3\\xa9lix was his son. Meira is mystified by the fact that F\\xc3\\xa9lix has no children, as he is single, a novel concept for her as she comes from a culture where women have as many as 14 children. She avoids eye contact with him, and becomes enraged when, while they are playing Ping-Pong, F\\xc3\\xa9lix's sister Caroline unexpectedly arrives and sees her.\\r\\nF\\xc3\\xa9lix and Meira go out dancing. Caroline also informs F\\xc3\\xa9lix that their mother had an affair, drawing parallel to F\\xc3\\xa9lix's interest in a married woman. Eventually, Shulem sees F\\xc3\\xa9lix and Meira walking on a street together, rushes up behind them and begins slapping F\\xc3\\xa9lix.\\r\\nLater, Shulem visits F\\xc3\\xa9lix in his apartment, informing him that if Meira and F\\xc3\\xa9lix reunite, Meira will never be allowed to return to the Hassidic community. Shulem also asks F\\xc3\\xa9lix to keep Meira safe and cared for. Before leaving, Shulem notices a folded up piece of paper, that F\\xc3\\xa9lix says was written by Th\\xc3\\xa9odore and never read. Shulem reads it, revealing Th\\xc3\\xa9odore apologized for bullying F\\xc3\\xa9lix to conform to the family, where he never felt comfortable. F\\xc3\\xa9lix and Meira take Elishiva to Venice.\">, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "       0., 0., 0.])>}\n",
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'crime on the hill'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b'A man tries to clear the name of his uncle who is wrongly convicted of a murdering the squire in a picturesque English village.'>, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "       0., 0., 0.])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dictionary can now be used with tf.data.Dataset.from_tensor_slices to create the training dataset. The same process can be followed for the validation and test sets. Be sure to print intermediate results (dataframes, datasets) to ensure that the datasets are in the expected format before using them for training."
      ],
      "metadata": {
        "id": "Uqln4yACV8BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the movie plots dataset\n",
        "df = pd.read_csv(path, compression='gzip')\n",
        "\n",
        "# Preprocess the titles column\n",
        "def preprocess_titles(title):\n",
        "    # Remove parentheses and their contents\n",
        "    title = re.sub(r'\\([^)]*\\)', '', title)\n",
        "    # Remove any remaining punctuation\n",
        "    title = re.sub(r'[^\\w\\s]', '', title)\n",
        "    # Convert to lowercase\n",
        "    title = title.lower()\n",
        "    return title\n",
        "\n",
        "df['Title'] = df['Title'].apply(preprocess_titles)\n",
        "\n",
        "# Convert Origin/Ethnicity and Genre to one-hot encoded variables\n",
        "df = pd.get_dummies(df, columns=['Origin/Ethnicity', 'Genre'])\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_df, val_df, test_df = np.split(df.sample(frac=1, random_state=42), [int(0.6*len(df)), int(0.8*len(df))])\n",
        "\n",
        "# Convert the dataframes to dictionaries\n",
        "train_dict = {'Title': train_df['Title'].values, 'Origin/Ethnicity': train_df.filter(like='Origin/Ethnicity').values.astype(np.float64), 'Plot': train_df['Plot'].values, 'Genre': train_df.filter(like='Genre').values.astype(np.float64)}\n",
        "val_dict = {'Title': val_df['Title'].values, 'Origin/Ethnicity': val_df.filter(like='Origin/Ethnicity').values.astype(np.float64), 'Plot': val_df['Plot'].values, 'Genre': val_df.filter(like='Genre').values.astype(np.float64)}\n",
        "test_dict = {'Title': test_df['Title'].values, 'Origin/Ethnicity': test_df.filter(like='Origin/Ethnicity').values.astype(np.float64), 'Plot': test_df['Plot'].values, 'Genre': test_df.filter(like='Genre').values.astype(np.float64)}\n",
        "\n",
        "# Create tf.data.Dataset objects from the dictionaries\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_dict)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(val_dict)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test_dict)\n",
        "\n",
        "# Print the first few entries in the training dataset\n",
        "for elem in train_dataset.take(5):\n",
        "    print(elem)\n"
      ],
      "metadata": {
        "id": "7FM7O2RDV8oN",
        "outputId": "1c98e1b3-8236-4f88-d7ad-f7661cc93d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'creature with the atom brain'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b\"A hulking zombie breaks into a mansion and kills a gangster named Hennesy. The blood stains left behind at the crime scene are radioactive, and the fingerprints of the killer are of a man who had died days before the murder; the police are baffled.\\r\\nGangster boss Frank Buchanan, who had been forced to flee the United States before he was deported, was betrayed by members of his own underworld gang. While traveling in Europe, he finds ex-Nazi scientist Wilhelm Steigg (Gaye), who is trying to reanimate the dead in order to provide a menial labor pool that is easily exploited. Buchanan funds the research and brings the scientist to America with the unstated goal of sending Steigg's zombies out to murder those who ousted him; one by one, they are killed in the same fashion.\\r\\nThe police eventually discover the common connection between the murdered gang members and Buchanan. They try to put the remaining three into protective custody, but Buchanan uses a reanimated dead cop to kill one of them, and a reanimated dead police captain to kill the remaining two. When the zombie captain is captured, police doctor, Dr. Chet Walker (Denning) discovers an atomic-powered remote control brain implant and deduces what has been going on.\\r\\nPolice and army troops converge on Buchanan's lead-lined mansion, and he sends out his unkillable zombies to battle them. Walker, however, is able to get into the mansion and smash the atomic-powered equipment that controls the zombies; after doing so, they all collapse. Buchanan is about to shoot Walker, but the still-animated zombie police captain, now under Walker's control, grabs and strangles Buchanan before he can fire a shot.\">, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.])>}\n",
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'son of paleface'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b'Peter \"Junior\" Potter (Hope) has graduated from Harvard and now heads west to the town of Sawbuck Pass to claim his Daddy\\'s fortune. Driving into town in a jalopy and wearing a comical plaid suit, he splashes mud all over a crowd of townspeople. He also discovers to his horror that practically everyone in town claims to be owed a debt, and that his father\\'s treasure chest is empty.\\r\\nJunior stalls the townfolk for as long as he can, continually making allusions to his wealth. He makes the acquaintance of a singing cowboy named Roy (Rogers) and a sexy saloon performer with the masculine name of Mike (Russell), who has to fend off Junior\\'s persistent advances. A grizzled local character also befriends Junior and continues offering him advice, eventually finding the hiding place of his father\\'s hidden fortune. Meanwhile, a mysterious masked bandit known only as \"The Torch\" has been leading midnight raids.\\r\\nWhat the wise-cracking, clueless Junior doesn\\'t know is that the object of his affections, Mike, is in fact The Torch, and that Roy is a government agent with a Smith & Wesson Model 320 Revolving Rifle hidden in his guitar case, bent on capturing her.'>, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.])>}\n",
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'the lady with a lamp'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b'Illustrating the political complexities the hard-headed nurse had to battle in order to achieve sanitary medical conditions during the Crimean War. Opposed in the uppermost circles of British government because she is \"merely\" a woman, Florence Nightingale is championed by the Hon. Sidney Herbert (Michael Wilding), minister of war. Herbert pulls strings to allow Nightingale and her nursing staff access to battlefield hospitals, and in so doing changes the course of medical history.[3]'>, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.])>}\n",
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'felix and meira'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b\"In Mile End, Montreal, a Hassidic Jewish woman named Meira lives a miserable life, married to Shulem who does not allow her to listen to secular music. They have a young daughter named Elishiva, but Meira confides in her friend that she does not want any more children, despite their religious duty. Word reaches Shulem, who berates Meira for shaming the small family. By chance, Meira meets F\\xc3\\xa9lix, a French Canadian man who has just lost his father Th\\xc3\\xa9odore, who at the end of his life no longer knew F\\xc3\\xa9lix was his son. Meira is mystified by the fact that F\\xc3\\xa9lix has no children, as he is single, a novel concept for her as she comes from a culture where women have as many as 14 children. She avoids eye contact with him, and becomes enraged when, while they are playing Ping-Pong, F\\xc3\\xa9lix's sister Caroline unexpectedly arrives and sees her.\\r\\nF\\xc3\\xa9lix and Meira go out dancing. Caroline also informs F\\xc3\\xa9lix that their mother had an affair, drawing parallel to F\\xc3\\xa9lix's interest in a married woman. Eventually, Shulem sees F\\xc3\\xa9lix and Meira walking on a street together, rushes up behind them and begins slapping F\\xc3\\xa9lix.\\r\\nLater, Shulem visits F\\xc3\\xa9lix in his apartment, informing him that if Meira and F\\xc3\\xa9lix reunite, Meira will never be allowed to return to the Hassidic community. Shulem also asks F\\xc3\\xa9lix to keep Meira safe and cared for. Before leaving, Shulem notices a folded up piece of paper, that F\\xc3\\xa9lix says was written by Th\\xc3\\xa9odore and never read. Shulem reads it, revealing Th\\xc3\\xa9odore apologized for bullying F\\xc3\\xa9lix to conform to the family, where he never felt comfortable. F\\xc3\\xa9lix and Meira take Elishiva to Venice.\">, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "       0., 0., 0.])>}\n",
            "{'Title': <tf.Tensor: shape=(), dtype=string, numpy=b'crime on the hill'>, 'Origin/Ethnicity': <tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0.])>, 'Plot': <tf.Tensor: shape=(), dtype=string, numpy=b'A man tries to clear the name of his uncle who is wrongly convicted of a murdering the squire in a picturesque English village.'>, 'Genre': <tf.Tensor: shape=(20,), dtype=float64, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "       0., 0., 0.])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, preprocess_titles() is a function that extracts the movie titles from the text data, and y is the target variable for classification (e.g., 1 for action movies, 0 for romance movies). The number of epochs is set to 50, but this value can be adjusted based on the performance of the model on the training data."
      ],
      "metadata": {
        "id": "SYk85dgnGJij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Preprocess the text data to extract only the movie title\n",
        "titles = preprocess_titles(\"The Shawshank Redemption\")\n",
        "\n",
        "# Convert the titles into a binary bag-of-words representation with a vocabulary of 500 words\n",
        "vectorizer = CountVectorizer(binary=True, max_features=500)\n",
        "X = vectorizer.fit_transform(titles)\n",
        "\n",
        "# Create a linear classification model with a single output layer\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=X.shape[1], activation='sigmoid'))\n",
        "\n",
        "# Compile the model using the Adam optimizer with a learning rate of 0.001 and the binary cross-entropy loss function\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the fit method of the Keras model\n",
        "model.fit(X, y, epochs=50, batch_size=32)\n"
      ],
      "metadata": {
        "id": "M0nbUtXsGKQh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}